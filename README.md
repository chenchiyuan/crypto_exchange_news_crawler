# Crypto Exchange News Crawler ğŸš€

A powerful and easy-to-use Python package for scraping cryptocurrency exchange announcements from major exchanges, with advanced futures market monitoring capabilities.

## ğŸ¯ Features

### å…¬å‘Šçˆ¬å– (Announcement Crawler)
- **Multi-Exchange Support**: Scrape from 12 major crypto exchanges
- **Multiple Output Formats**: JSON, CSV, and XML support
- **Structured Data**: Clean, standardized output format
- **Rate Limiting**: Built-in delays to respect exchange servers
- **Extensible**: Easy to add new exchanges

### åˆçº¦ç›‘æ§ (Futures Market Monitor) ğŸ†•
- **å®æ—¶å¸‚åœºæŒ‡æ ‡**: è¿½è¸ª8ä¸ªæ ¸å¿ƒå¸‚åœºæŒ‡æ ‡
  - æŒä»“é‡ (Open Interest)
  - 24å°æ—¶äº¤æ˜“é‡ (24H Volume)
  - èµ„é‡‘è´¹ç‡ (Funding Rate)
  - å¹´åŒ–è´¹ç‡ (Annual Funding Rate)
  - ä¸‹æ¬¡ç»“ç®—æ—¶é—´ (Next Funding Time)
  - è´¹ç‡ä¸Šä¸‹é™ (Funding Rate Cap/Floor)
  - èµ„é‡‘è´¹ç‡é—´éš” (Funding Interval)
- **å¤šäº¤æ˜“æ‰€æ”¯æŒ**: Binance, Bybit, Hyperliquid
- **é«˜æ€§èƒ½è·å–**: 1,312ä¸ªåˆçº¦ < 4ç§’
- **Django Adminç®¡ç†**: å¯è§†åŒ–å±•ç¤ºå’Œç®¡ç†
- **æ–°å¸ä¸Šçº¿é€šçŸ¥**: è‡ªåŠ¨æ£€æµ‹å¹¶æ¨é€

è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ [å¸‚åœºæŒ‡æ ‡ä½¿ç”¨æŒ‡å—](docs/MARKET_INDICATORS_GUIDE.md)

## ğŸ“¦ Installation Options

### Option 1: Direct Usage

```bash
git clone https://github.com/lowweihong/crypto-exchange-news-crawler.git
cd crypto-exchange-news-crawler
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
playwright install

scrapy crawl bybit -o output.json
```

### Option 2: Install from PyPI

```bash
pip install crypto-exchange-news-crawler
playwright install

## directly use proxy and uncomment DOWNLOADER_MIDDLEWARES
crypto-news crawl binance -o binance.json

crypto-news crawl bybit -s DOWNLOADER_MIDDLEWARES='{"crypto_exchange_news.middlewares.MyProxyMiddleware": 610}' -s PROXY_LIST="http://proxy1:port,http://proxy2:port"
```

### Supported Exchanges

| Exchange  | Status |
|-----------|--------|
| Bybit     | âœ… |
| Binance   | âœ… |
| OKX       | âœ… |
| Bitget    | âœ… |
| BingX     | âœ… |
| Kraken    | âœ… |
| Bitfinex  | âœ… |
| XT        | âœ… |
| Crypto.com| âœ… |
| MEXC      | âœ… |
| Deepcoin  | âœ… |
| Kucoin    | âœ… |
| Upbit     | âœ… |

```
Available options : ["bybit", "binance", "okx", "bitget", "bitfinex", "xt", "bingx", 'kraken', 'cryptocom', 'mexc', 'deepcoin', 'kucoin', 'upbit']
```
#

## ğŸ“Š Output Format

Each scraped announcement includes:

```json
{
    "news_id": "unique_identifier",
    "title": "Announcement title",
    "desc": "Announcement description",
    "url": "Full URL to announcement",
    "category_str": "Category (e.g., latest_activities, new_crypto)",
    "exchange": "Exchange name",
    "announced_at_timestamp": 1749235200,
    "timestamp": 1749232733
}
```

## âš™ï¸ Configuration

Key settings in `settings.py`:

- `MAX_PAGE`: Maximum number of pages to crawl (default: 2)
- `DOWNLOAD_DELAY`: Delay between requests in seconds (default: 3)
- `CONCURRENT_REQUESTS`: Number of concurrent requests (default: 8)
- `USER_AGENT`: List of user agents for rotation
- `PROXY_LIST`: Fill the list with your proxy list and remember also to open uncomment the DOWNLOADER_MIDDLEWARES part to use the proxy middleware
- `PLAYWRIGHT_LAUNCH_OPTIONS`: Browser configuration for Playwright spiders

### Custom Settings

You can override settings from the command line:

```bash
scrapy crawl bitget -s MAX_PAGE=5 -s DOWNLOAD_DELAY=2
```

## ğŸ”§ Technical Requirements

- Python 3.7+
- Scrapy 2.11.0+
- Playwright (for Bitget spider)
- Chromium browser (automatically installed with Playwright)

## ğŸŒ Exchange URLs

Direct links to announcement pages:

| Exchange | Announcement URL |
|----------|------------------|
| **Binance** | https://www.binance.com/en/support/announcement |
| **OKX** | https://www.okx.com/help/category/announcements |
| **Bybit** | https://announcements.bybit.com/en/?category=&page=1 |
| **Bitget** | https://www.bitget.com/support/sections/12508313443483 |
| **BingX** | https://bingx.com/en/support/notice-center/ |
| **Kraken** | https://blog.kraken.com/category/product |
| **XT** | https://xtsupport.zendesk.com/hc/en-us/categories/10304894611993-Important-Announcements |
| **Bitfinex** | https://www.bitfinex.com/posts/ |
| **Crypto.com** | https://crypto.com/exchange/announcements |
| **MEXC** | https://www.mexc.com/support/categories/360000254192 |
| **Deepcoin** | https://support.deepcoin.online/hc/en-001/categories/360003875752-Important-Announcements |
| **Kucoin** | https://www.kucoin.com/announcement |
| **Upbit** | https://sg.upbit.com/service_center/notice |

## ğŸ“ˆ Futures Market Monitor Quick Start

### è·å–åˆçº¦å¸‚åœºæŒ‡æ ‡

```python
# è·å–Binanceåˆçº¦åŠå¸‚åœºæŒ‡æ ‡
python manage.py fetch_futures --exchange binance

# ç›‘æ§æ‰€æœ‰äº¤æ˜“æ‰€çš„æ–°å¸ä¸Šçº¿
python manage.py monitor_futures --hours 24

# æŸ¥çœ‹Django Adminåå°
python manage.py runserver
# è®¿é—® http://localhost:8000/admin
```

### æ€§èƒ½æŒ‡æ ‡

- **å¤„ç†é€Ÿåº¦**: 1,312ä¸ªåˆçº¦ < 4ç§’
- **æ”¯æŒäº¤æ˜“æ‰€**: Binance (535åˆçº¦), Bybit (557åˆçº¦), Hyperliquid (220åˆçº¦)
- **å¹´åŒ–è´¹ç‡è®¡ç®—**: è‡ªåŠ¨è®¡ç®—å¹¶æ˜¾ç¤º
- **Adminåå°**: å½©è‰²æ ‡è®°ã€åƒåˆ†ä½æ ¼å¼åŒ–ã€å®æ—¶æ›´æ–°

### å¸‚åœºæŒ‡æ ‡åŒ…å«

| æŒ‡æ ‡ | è¯´æ˜ | Adminæ˜¾ç¤º |
|------|------|-----------|
| æŒä»“é‡ | Open Interest | åƒåˆ†ä½æ ¼å¼åŒ– |
| 24Häº¤æ˜“é‡ | 24 Hour Volume | è“è‰²é«˜äº® |
| èµ„é‡‘è´¹ç‡ | Current Funding Rate | æ­£è´¹ç‡ç»¿è‰²/è´Ÿè´¹ç‡çº¢è‰² |
| å¹´åŒ–è´¹ç‡ | Annual Funding Rate | æ ¹æ®æ•°å€¼é¢œè‰²æ ‡è®° |
| ä¸‹æ¬¡ç»“ç®— | Next Funding Time | å€’è®¡æ—¶æ˜¾ç¤º |
| è´¹ç‡ä¸Šä¸‹é™ | Funding Rate Cap/Floor | - |
| è´¹ç‡é—´éš” | Funding Interval Hours | - |

å®Œæ•´ä½¿ç”¨æ–‡æ¡£è¯·æŸ¥çœ‹ï¼š[å¸‚åœºæŒ‡æ ‡ä½¿ç”¨æŒ‡å—](docs/MARKET_INDICATORS_GUIDE.md)

## âš–ï¸ Legal & Ethical Usage

This crawler is designed for educational and research purposes. Please ensure you comply with:

- Applicable data protection laws
- Fair use guidelines

Always use the crawler responsibly and consider the impact on the target servers.

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Add support for more exchanges (Huobi, Gateio, etc.)
- Implement real-time WebSocket feeds
- Add telegram/discord notification integrations
- Improve data parsing and categorization

## Support

For issues, questions, or contributions, please create an issue in the repository.