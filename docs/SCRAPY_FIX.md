# ğŸ› ï¸ Scrapy ç¯å¢ƒä¿®å¤è¯´æ˜

## ğŸ“‹ é—®é¢˜æè¿°

åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œç›‘æ§å‘½ä»¤æ—¶é‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

```bash
FileNotFoundError: [Errno 2] No such file or directory: 'scrapy'
```

**é”™è¯¯ä½ç½®**ï¼š`monitor/services/crawler.py:78`

## ğŸ” åŸå› åˆ†æ

### 1. é—®é¢˜æ ¹æº
- ä»£ç ä¸­ç›´æ¥è°ƒç”¨äº† `scrapy` å‘½ä»¤
- æœåŠ¡å™¨ä½¿ç”¨ `miniconda` ç¯å¢ƒï¼ŒPATH å¯èƒ½ä¸åŒ…å« scrapy
- å½“å‰ Python ç¯å¢ƒå·²å®‰è£… scrapyï¼Œä½†ä¸åœ¨ç³»ç»Ÿ PATH ä¸­

### 2. åœºæ™¯ç¤ºä¾‹
**æœåŠ¡å™¨ç¯å¢ƒ**ï¼š
- Python è·¯å¾„ï¼š`/home/ubuntu/miniconda3/envs/crypto_exchange_monitor/bin/python`
- Scrapy è·¯å¾„ï¼š`/home/ubuntu/miniconda3/envs/crypto_exchange_monitor/bin/scrapy`
- ä½† PATH ç¯å¢ƒå˜é‡å¯èƒ½ä¸åŒ…å«ä¸Šè¿° bin ç›®å½•

**ç›´æ¥è°ƒç”¨ `scrapy`**ï¼š
```bash
# æŸ¥æ‰¾é¡ºåºï¼š
# 1. å½“å‰ç›®å½•
# 2. PATH ç¯å¢ƒå˜é‡ä¸­çš„ç›®å½•
# 3. æ‰¾ä¸åˆ° scrapy â†’ æŠ¥é”™
```

## âœ… è§£å†³æ–¹æ¡ˆ

### ä¿®æ”¹å†…å®¹
**æ–‡ä»¶**ï¼š`monitor/services/crawler.py`

**ä¿®æ”¹å‰**ï¼š
```python
import subprocess

cmd = ['scrapy', 'crawl', spider_name, ...]
```

**ä¿®æ”¹å**ï¼š
```python
import subprocess
import sys

cmd = [sys.executable, '-m', 'scrapy', 'crawl', spider_name, ...]
```

### ä¼˜åŠ¿
1. **ä¸ä¾èµ– PATH ç¯å¢ƒå˜é‡**ï¼šç›´æ¥ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨
2. **ç¯å¢ƒæ— å…³**ï¼šå…¼å®¹ venvã€condaã€virtualenv ç­‰æ‰€æœ‰è™šæ‹Ÿç¯å¢ƒ
3. **æ›´å¯é **ï¼šç¡®ä¿ä½¿ç”¨å½“å‰ç¯å¢ƒçš„ scrapy æ¨¡å—

## ğŸš€ éªŒè¯ä¿®å¤

### 1. æœåŠ¡å™¨éƒ¨ç½²åæµ‹è¯•
```bash
# æµ‹è¯•è·å–å…¬å‘Š
python manage.py monitor --hours 48

# é¢„æœŸç»“æœï¼šæ—  FileNotFoundError
# åº”è¯¥çœ‹åˆ°ï¼šè·å–åˆ° X æ¡å…¬å‘Š
```

### 2. æœ¬åœ°æµ‹è¯•
```bash
# åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒæµ‹è¯•
python manage.py monitor --hours 24 --skip-notification

# åº”è¯¥æ­£å¸¸å·¥ä½œ
```

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### è°ƒç”¨æ–¹å¼å¯¹æ¯”

| æ–¹å¼ | å‘½ä»¤ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|------|
| **æ—§æ–¹å¼** | `scrapy crawl spider` | ç®€å• | ä¾èµ– PATH |
| **æ–°æ–¹å¼** | `python -m scrapy crawl` | ç¯å¢ƒæ— å…³ | å‘½ä»¤ç¨é•¿ |

### Python æ¨¡å—è°ƒç”¨åŸç†
```bash
python -m scrapy crawl
ç­‰ä»·äº
python /path/to/scrapy/__main__.py crawl
```

ç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨ `sys.path` ä¸­æŸ¥æ‰¾ `scrapy` æ¨¡å—ï¼Œå¹¶æ‰§è¡Œå…¶ `__main__.py` æ–‡ä»¶ã€‚

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ç¡®ä¿ scrapy å·²å®‰è£…**ï¼š
   ```bash
   pip install scrapy
   ```

2. **éªŒè¯å½“å‰ç¯å¢ƒ**ï¼š
   ```bash
   python -c "import scrapy; print(scrapy.__file__)"
   ```

3. **å¦‚æœä»æœ‰é—®é¢˜ï¼Œæ£€æŸ¥æƒé™**ï¼š
   ```bash
   chmod +x $(which python)
   ```

## ğŸ”„ ç›¸å…³æ–‡ä»¶

- **ä¿®æ”¹æ–‡ä»¶**ï¼š`monitor/services/crawler.py`
- **æ¶‰åŠå‘½ä»¤**ï¼š
  - `python manage.py monitor`
  - `python manage.py daily_summary`
  - `python manage.py identify_listings`

## âœ… ä¿®å¤çŠ¶æ€

- [x] å·²ä¿®å¤ crawler.py ä¸­çš„ scrapy è°ƒç”¨
- [x] å·²æµ‹è¯•æœ¬åœ°ç¯å¢ƒæ­£å¸¸å·¥ä½œ
- [x] å·²æäº¤åˆ° Git ä»“åº“
- [ ] **å¾…æœåŠ¡å™¨éªŒè¯**ï¼ˆéœ€è¦éƒ¨ç½²åæµ‹è¯•ï¼‰

---

**éƒ¨ç½²å»ºè®®**ï¼šå°†ä¿®æ”¹åçš„ä»£ç æ¨é€åˆ°æœåŠ¡å™¨ï¼Œå¹¶é‡æ–°æµ‹è¯•ç›‘æ§å‘½ä»¤ã€‚